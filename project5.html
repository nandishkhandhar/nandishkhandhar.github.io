

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 2 - CS180 Projects</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            max-width: 800px;
            margin: 0 auto;
        }
        h1, h2 {
            color: #333;
        }
        img {
            max-width: 100%;
            height: auto;
            margin: 20px 0;
        }
    </style>
</head>
<body>
    <h1>Project 5A - The Power of Diffusion Models</h1>
    
    <h2>Sampling from the model</h2>
    <p> For this part, the model that was already given was used to sample different prompts with different num_inference steps. The results are shown below. The first 
    row uses 5 steps, while the second and third use 20 and 40 respectively. The quality of images increases significantly as the inference steps go up, and details are more and more refined.</p>

    <style>
      .imagecontainer {
        text-align: center;
      }
      .imagecontainer img {
        display: inline-block;
        width: 15%; 
        margin: 10px;
      }
    </style>
    
    <div class="imagecontainer">
        <img src="./images/download-3.png" alt="lowres3" width=300 height=300>
        <img src="./images/download-4.png" alt="lowres3" width=300 height=300>
        <img src="./images/download-5.png" alt="lowres3" width=300 height=300>
    </div>

    <div class="imagecontainer">
        <img src="./images/download.png" alt="lowres3" >
        <img src="./images/download-1.png" alt="lowres3">
        <img src="./images/download-2.png" alt="lowres3">
    </div>

    <div class="imagecontainer">
        <img src="./images/download-6.png" alt="lowres3" >
        <img src="./images/download-7.png" alt="lowres3">
        <img src="./images/download-8.png" alt="lowres3">
    </div>
     

    <h2>1.1 - Forward Processes</h2>
    <p>The forward function simulates the forward diffusion process by adding noise to the input image (im) based on a time-dependent noise schedule (alpha_cumprod[t]). 
        It scales the image and noise components, introducing progressively more noise as t increases.</p>
    
    <style>
      .imagescontainer {
        text-align: center;
      }
      .imagescontainer img {
        display: inline-block;
        width: 20%; 
        margin: 10px;
      }
    </style>
    
    <div class="imagescontainer">
        <img src="./images/download-9.png" alt="lowres3" >
        <img src="./images/download-10.png" alt="lowres3">
        <img src="./images/download-13.png" alt="lowres3">
        <img src="./images/download-16.png" alt="lowres3">
    </div>


    <h2>1.2 - Classical Denoising</h2>

    <p> The classical denoising method using Gaussian blur filtering reduces noise by smoothing the image through convolution with a Gaussian kernel. 
        This removes high-frequency noise while keeping lower-frequency image details. This leads to a cleaner but slightly blurred output.
    In the pairs of images below, the right image is the Gaussian denoised image, while the left is the noisy versions.</p>
    
    <style>
      .image-container1 {
        text-align: center;
      }
      .image-container1 img {
        display: inline-block;
        width: 25%; 
        margin: 10px;
      }
    </style>
    
    <div class="image-container1">
        <img src="./images/download-10.png" alt="lowres3" >
        <img src="./images/download-11.png" alt="lowres3">
    </div>
     <div class="image-container1">
        <img src="./images/download-13.png" alt="lowres3" >
        <img src="./images/download-14.png" alt="lowres3">
    </div>
     <div class="image-container1">
        <img src="./images/download-16.png" alt="lowres3" >
        <img src="./images/download-17.png" alt="lowres3">
    </div>
    
    <h2>1.3 - One Step Denoising</h2>
    <p>In one-step denoising, the pretrained diffusion model (UNet) estimates the Gaussian noise present in a noisy image using the noise level (timestep) and prompt embeddings as inputs. 
        This estimated noise is then subtracted from the noisy image, accounting for the scaling factors of the forward diffusion process, to reconstruct an approximation of the original image.
    </p>

    <style>
      .image-container2 {
        text-align: center;
      }
      .image-container2 img {
        display: inline-block;
        width: 20%; 
        margin: 10px;
      }
    </style>
    
    <div class="image-container2">
        <img src="./images/download-10.png" alt="lowres3" >
        <img src="./images/download-12.png" alt="lowres3">
    </div>
     <div class="image-container2">
        <img src="./images/download-13.png" alt="lowres3" >
        <img src="./images/download-15.png" alt="lowres3">
    </div>
     <div class="image-container2">
        <img src="./images/download-16.png" alt="lowres3" >
        <img src="./images/download-18.png" alt="lowres3">
    </div>
    
    
    
    <h2>1.4 - Iterative Denoising</h2>

    <p>
The iterative_denoise function progressively removes noise from an input image by using UNet.
        At each timestep, it predicts the noise and variance in the image, estimates a cleaner version using a weighted combination of the image and the noise estimate, and adds controlled variance to maintain the generative process. 
        This iterative process gradually transitions the noisy image to a cleaner, denoised version.</p>

        
    <style>
      .image-container3 {
        text-align: center;
      }
      .image-container3 img {
        display: inline-block;
        width: 20%; 
        margin: 10px;
      }
    </style>
    
    <div class="image-container3">
        <img src="./images/download-e.png" alt="lowres3" title = "Noisy Campanile at t=90" >
        <img src="./images/download-d.png" alt="lowres3" title = "Noisy Campanile at t=240" >
        <img src="./images/download-c.png" alt="lowres3" title = "Noisy Campanile at t=390" >
        <img src="./images/download-b.png" alt="lowres3" title = "Noisy Campanile at t=540" >
        <img src="./images/download-a.png" alt="lowres3" title = "Noisy Campanile at t=690" >
    </div>

      
    <div class="image-container3">
        <img src="./images/download-i.png" alt="lowres3" title = "Original Image" >
        <img src="./images/download-f.png" alt="lowres3" title = "Iteratively Denoised Campanile" >
        <img src="./images/download-g.png" alt="lowres3" title = "One-Step Denoised Campanile" >
        <img src="./images/download-h.png" alt="lowres3" title = "Gaussian Blurred Campanile" >
    </div>
    
    

    <h2>Part 2: ANMS Detection</h2>

    <div>
    <p>This code performs <strong>corner detection</strong> on two images using the <strong>Harris Corner Detection</strong> algorithm, then refines the detected corners with <strong>Adaptive Non-Maximal Suppression (ANMS)</strong> to retain the strongest and most spatially spread-out points.</p>
        
    <h3>Corner Detection</h3>
    <p>The <code>get_harris_corners()</code> function detects potential corners and assigns a score to each, indicating the corner strength.</p>

    <h3>ANMS Filtering</h3>
    <p><code>adaptive_non_maximal_suppression()</code> filters these corners. Pairwise distances between corner points are calculated, and only the most prominent corners with a wide spatial distribution are retained by setting a minimum radius for each point, using a comparison threshold (<code>c_robust</code>).</p>

    <h3>Visualization</h3>
    <p>The <code>visualize_corners()</code> function overlays the final selected corners on the original images as red dots, clearly marking the detected corner points.</p>
</div>


    <style>
      .image-container {
        text-align: center;
      }
      .image-container img {
        display: inline-block;
        width: 40%; 
        margin: 10px;
      }
    </style>
    
    <div class="image-container">
        <img src="./images/c.png" alt="lowres3" >
        <img src="./images/d.png" alt="lowres3">
    </div>

    
    <h2>Part 3: Feature Extraction</h2>

     <div>
    <p>This code extracts <strong>feature descriptors</strong> from selected corner points in two images, representing unique patches around each corner. It then visualizes a subset of these feature patches.</p>

    <h3>Feature Extraction</h3>
    <p>The <code>extract_feature_descriptors()</code> function takes a 40x40 pixel patch around each corner, resizes it to 8x8, normalizes it by subtracting the mean and dividing by the standard deviation, and then flattens it. This results in an array of feature descriptors.</p>

    <h3>Patch Visualization</h3>
    <p>The <code>display_feature_patches()</code> function displays the first few feature patches in a grid, representing local features around corners.</p>
    </div>

    <img src="./images/ae.png" alt="lowres3">
    <img src="./images/af.png" alt="lowres3">

    <h2>Part 4: Feature Matching</h2>
    
    <p> The provided functions compute feature matches between two sets of feature descriptors derived from images, utilizing a method based on the distance between feature vectors. 
        The compute_feature_matches() function calculates the squared differences between each pair of features from two images, generating a distance matrix. It then applies Lowe's ratio test to filter out matches, retaining only those where the nearest neighbor is significantly closer than the second nearest. The draw_matches() function visualizes these matches by resizing and combining the two images side by side, drawing lines between matched keypoints to illustrate correspondences. 
        The resulting plot provides a clear representation of how features from the two images align with each other.</p>

    <img src="./images/g.png" alt="lowres3">

    <h2>Part 5: RANSAC</h2>
    
    <p> 
The provided functions implement a robust method for estimating the homography between two sets of matched keypoints using RANSAC (Random Sample Consensus). The compute_homography() function calculates the homography matrix based on four corresponding points, while ransac_homography() iteratively samples random point pairs, computes their homography, and identifies inliers based on a distance threshold. 
        This process aims to minimize the influence of outliers in the matching process. 
    </p>

    <img src="./images/h.png" alt="lowres3">
    <img src="./images/q.png" alt="lowres3">
    <img src="./images/r.png" alt="lowres3">

    <h2>Part 6: Autostitching</h2>
    
    <p>For the autostitching, the method is the same as in part A, except that the homographies are now calculated using RANSAC. From the below images, you can see that the autostitched mosaics are 
    slightly worse than the manual ones. This is probably because for the manual process the correspondences were chosen by hand, and probably more accurate in feature matching than the algorithm. The first images 
    in the image pairs are the autostitched ones and the second images are the manually stitched mosaics.</p>

    
    <div class="image-container">
        <h3>Image Pair 1</h3>
        <img src="./images/j.png" alt="lowres3">
        <img src="./images/mosaic_outside.png" alt="lowres3">

        
    </div>

    <div class="image-container">
        <h3>Image Pair 2</h3>
        <img src="./images/p.png" alt="lowres3">
        <img src="./images/mosaic_room.png" alt="lowres3">
    </div>

    <div class="image-container">
        <h3>Image Pair 3</h3>
        <img src="./images/m.png" alt="lowres3">
        <img src="./images/panorama_outside_alpha_blended.png" alt="lowres3">
    </div>
    

    <h2>Conclusion</h2>
    <p>The most interesting thing I learnt from this was that there needs to be a good balance between automating the process and finding the best correspondences.
        For the manual images, the correspondences are better, since theyre selected by hand (I can match eye to eye etc...). However, the autostitched method
        is faster, but leaves it up to the algorithm to pick up matching features. I have taken some inspiration from ChatGPT and pretrained LLM's to create the structure for some parts of the website.</p>
      
    <a href="index.html">Back to Main Page</a>
</body>
</html>
